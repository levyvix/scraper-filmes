# Scraper de Filmes - GratisTorrent

Sistema automatizado de scraping de filmes do site GratisTorrent com armazenamento em SQLite e exporta√ß√£o opcional para BigQuery.

## üìÅ Estrutura do Projeto

```
scraper-filmes/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ scrapers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gratis_torrent/     # Scraper do GratisTorrent
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ extract.py       # Script de scraping
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ send_to_bq.py    # Exporta√ß√£o para BigQuery
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ schema.json      # Schema do BigQuery
‚îÇ   ‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ insert_to_database.py  # L√≥gica de inser√ß√£o no SQLite
‚îÇ   ‚îî‚îÄ‚îÄ flows/
‚îÇ       ‚îî‚îÄ‚îÄ prefect_flow_gratis.py # Flow do Prefect
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ test_bigquery.py         # Script de teste do BigQuery
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ prefect.yaml             # Configura√ß√£o do Prefect
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ CLAUDE.md                # Documenta√ß√£o do projeto
‚îÇ   ‚îî‚îÄ‚îÄ BIGQUERY_SETUP.md        # Guia de configura√ß√£o do BigQuery
‚îú‚îÄ‚îÄ dbs/
‚îÇ   ‚îî‚îÄ‚îÄ movie_database.db        # Banco de dados SQLite
‚îî‚îÄ‚îÄ pyproject.toml               # Depend√™ncias do projeto
```

## üöÄ In√≠cio R√°pido

### 1. Instalar Depend√™ncias

```bash
# O projeto usa UV para gerenciamento de depend√™ncias
uv sync
```

### 2. Configurar Vari√°veis de Ambiente (Opcional)

```bash
# Copiar arquivo de exemplo
cp .env.example .env

# Editar .env com suas configura√ß√µes (especialmente GCP_PROJECT_ID para BigQuery)
# O arquivo .env √© carregado automaticamente pelos scripts
```

### 3. Executar o Scraper

```bash
# Scraper do GratisTorrent
uv run src/scrapers/gratis_torrent/extract.py
```

### 3. Executar o Flow Completo

```bash
# Flow do Prefect (scraping + banco de dados + estat√≠sticas)
uv run src/flows/prefect_flow_gratis.py
```

## üìä Funcionalidades

- ‚úÖ Scraping autom√°tico do site GratisTorrent
- ‚úÖ Valida√ß√£o de dados com Pydantic
- ‚úÖ Armazenamento em SQLite com deduplica√ß√£o
- ‚úÖ Workflow orquestrado com Prefect
- ‚úÖ Exporta√ß√£o opcional para Google BigQuery
- ‚úÖ Deployment com Docker
- ‚úÖ Suporte a retry e tratamento de erros

## üîÑ Como Funciona o Pipeline

### Vis√£o Geral do Fluxo de Dados

O projeto implementa um pipeline completo de ETL (Extract, Transform, Load) orquestrado pelo Prefect:

```
Web Scraping ‚Üí Valida√ß√£o ‚Üí SQLite ‚Üí BigQuery (opcional)
                                  ‚Üì
                            Estat√≠sticas
```

### 1. **Extra√ß√£o (Web Scraping)** - `src/scrapers/gratis_torrent/extract.py`

**Task Prefect**: `run_gratis_scraper()`

O scraper realiza as seguintes opera√ß√µes:

1. **Coleta de Links**: Acessa `https://gratistorrent.com/filmes/` e extrai todos os links de filmes da p√°gina inicial usando BeautifulSoup
2. **Extra√ß√£o de Dados**: Para cada filme, acessa a p√°gina individual e extrai informa√ß√µes usando regex:
   - T√≠tulo dublado e original
   - Nota IMDB, ano de lan√ßamento
   - G√™neros, dura√ß√£o em minutos
   - Qualidade do v√≠deo, tamanho do arquivo
   - Sinopse e link do torrent
3. **Valida√ß√£o com Pydantic**: Cada filme √© validado usando o model `Movie` que garante:
   - IMDB entre 0-10
   - Ano >= 1888 (primeiro filme da hist√≥ria)
   - Dura√ß√£o >= 1 minuto
4. **Sa√≠da**: Gera o arquivo `movies_gratis.json` com todos os filmes validados

**Configura√ß√£o de Retry**: 3 tentativas com 10 segundos de delay entre falhas

### 2. **Transforma√ß√£o e Carga no SQLite** - `src/database/insert_to_database.py`

**Task Prefect**: `insert_movies()`

O processo de inser√ß√£o no banco de dados:

1. **Cria√ß√£o de Tabelas** (se n√£o existirem):
   - `movies`: Armazena os dados principais dos filmes
   - `genres`: Armazena os g√™neros (relacionamento N:N com filmes)

2. **Transforma√ß√µes**:
   - Converte tamanho de GB (string) para MB (float)
   - Adiciona data de atualiza√ß√£o (`date_updated`) automaticamente
   - Separa g√™neros em registros individuais na tabela `genres`

3. **Deduplica√ß√£o Inteligente**:
   - Verifica se o filme j√° existe usando `titulo_dublado` + `date_updated`
   - Ignora filmes duplicados automaticamente
   - Permite que o mesmo filme seja inserido novamente em datas diferentes

4. **Transa√ß√£o At√¥mica**: Todas as inser√ß√µes s√£o feitas em uma √∫nica transa√ß√£o (commit ao final)

**Configura√ß√£o de Retry**: 3 tentativas com 10 segundos de delay entre falhas

### 3. **Estat√≠sticas** - Task `get_stats()`

Gera e exibe estat√≠sticas do banco de dados:
- Total de filmes cadastrados
- Total de g√™neros √∫nicos
- M√©dia das notas IMDB
- Data da √∫ltima atualiza√ß√£o

### 4. **Exporta√ß√£o para BigQuery (Opcional)** - `src/scrapers/gratis_torrent/send_to_bq.py`

**Task Prefect**: `export_to_bigquery()` - Executada apenas se `export_bq=True`

#### Processo de ETL no BigQuery:

1. **Cria√ß√£o da Infraestrutura**:
   - Dataset: `movies_raw`
   - Tabela staging: `stg_filmes` (tempor√°ria)
   - Tabela final: `filmes` (produ√ß√£o)

2. **Load para Staging**:
   - Carrega o arquivo `movies_gratis.json` na tabela `stg_filmes`
   - Usa schema definido em `schema.json` para valida√ß√£o
   - Formato: NEWLINE_DELIMITED_JSON

3. **Merge (Upsert)**:
   ```sql
   MERGE INTO filmes AS target
   USING stg_filmes AS source
   ON target.link = source.link
   WHEN NOT MATCHED THEN INSERT ...
   ```
   - Compara filmes por `link` (chave √∫nica)
   - Insere apenas filmes novos (evita duplica√ß√£o)
   - Retorna n√∫mero de linhas afetadas

4. **Limpeza**:
   - Trunca a tabela `stg_filmes` ap√≥s o merge
   - Prepara para a pr√≥xima execu√ß√£o

**Vantagens da Abordagem Staging**:
- ‚úÖ Separa√ß√£o entre dados tempor√°rios e produ√ß√£o
- ‚úÖ Valida√ß√£o antes de afetar dados finais
- ‚úÖ Rollback f√°cil em caso de problemas
- ‚úÖ Auditoria do processo de carga

### üéØ Orquestra√ß√£o com Prefect

**Flow Principal**: `gratis_torrent_flow()` - `src/flows/prefect_flow_gratis.py`

#### Execu√ß√£o das Tasks:

```python
# 1. Scraping
run_gratis_scraper()
    ‚Üì
# 2. Inser√ß√£o no SQLite
insert_movies(json_path, engine)
    ‚Üì
# 3. Estat√≠sticas
get_stats(engine)
    ‚Üì
# 4. BigQuery (condicional)
if export_bq:
    export_to_bigquery()
```

#### Recursos do Prefect:

1. **Retry Autom√°tico**: Tasks com falha s√£o reexecutadas automaticamente (3x)
2. **Logging**: Todos os prints s√£o capturados nos logs do Prefect
3. **Monitoramento**: UI web em `http://127.0.0.1:4200` mostra:
   - Status de cada task em tempo real
   - Logs completos de execu√ß√£o
   - Hist√≥rico de runs
   - M√©tricas de performance
4. **Agendamento**: Execu√ß√£o autom√°tica via cron (configur√°vel em `config/prefect.yaml`)
5. **Par√¢metros**: Flow aceita `export_bq` para controlar exporta√ß√£o ao BigQuery

#### Configura√ß√£o do Deployment:

Para executar o flow automaticamente (agendado), √© necess√°rio:

1. **Prefect Server**: Interface web e API (`uv run prefect server start`)
2. **Work Pool**: Gerencia a fila de execu√ß√£o (`uv run prefect work-pool create defaultp`)
3. **Deployment**: Configura√ß√£o do agendamento (`uv run prefect deploy -n default`)
4. **Worker**: Processo que executa as tasks (`uv run prefect worker start --pool defaultp`)

Veja [PREFECT_DEPLOYMENT.md](docs/PREFECT_DEPLOYMENT.md) para instru√ß√µes detalhadas.

### üéõÔ∏è Modos de Execu√ß√£o

#### 1. Execu√ß√£o Local Simples (Sem Agendamento)
```bash
uv run src/flows/prefect_flow_gratis.py
```
- Executa o flow imediatamente
- N√£o requer servidor Prefect
- Ideal para desenvolvimento e testes

#### 2. Execu√ß√£o via Deployment (Com Agendamento)
```bash
# Configurar infraestrutura (uma vez)
uv run prefect server start
uv run prefect work-pool create defaultp --set-as-default
uv run prefect deploy -n default

# Iniciar worker (mant√©m rodando)
uv run prefect worker start --pool defaultp
```
- Flow roda automaticamente no hor√°rio agendado
- Monitoramento via UI web
- Ideal para produ√ß√£o

## üîß Comandos Mais Importantes

### üéØ Uso R√°pido (Recomendado)

```bash
# Executar o workflow completo (scraping + banco de dados + estat√≠sticas)
uv run src/flows/prefect_flow_gratis.py
```

### ‚öôÔ∏è Gerenciamento de Depend√™ncias

```bash
# Instalar/sincronizar depend√™ncias
uv sync

# Adicionar nova biblioteca
uv add nome-da-biblioteca

# Remover biblioteca
uv remove nome-da-biblioteca

# Executar qualquer script Python
uv run src/caminho/para/script.py
```

### üï∑Ô∏è Scraping Manual

```bash
# Executar scraper do GratisTorrent
uv run src/scrapers/gratis_torrent/extract.py

# Inserir dados manualmente no SQLite
uv run python -c "from src.database.insert_to_database import create_and_insert; from sqlalchemy import create_engine; create_and_insert('src/scrapers/gratis_torrent/movies_gratis.json', create_engine('sqlite:///dbs/movie_database.db'))"
```

### üîÑ Prefect (Orquestra√ß√£o)

```bash
# Executar flow localmente
uv run src/flows/prefect_flow_gratis.py

# Iniciar servidor Prefect (interface web)
prefect server start

# Criar deployment para agendamento
prefect deployment build src/flows/prefect_flow_gratis.py:gratis_torrent_flow \
  --name gratis_flow \
  -q padrao \
  --apply

# Iniciar agent para executar deployments
prefect agent start -q padrao

# Ver status dos flows
prefect flow-run ls
```

### üìä BigQuery (Opcional)

```bash
# 1. Configurar vari√°veis de ambiente
cp .env.example .env
# Editar .env e configurar GCP_PROJECT_ID

# 2. Autenticar com Google Cloud
gcloud auth application-default login

# 3. Testar conex√£o com BigQuery
uv run scripts/test_bigquery.py

# 4. Enviar dados para BigQuery
uv run src/scrapers/gratis_torrent/send_to_bq.py

# Para configura√ß√£o completa, veja docs/BIGQUERY_SETUP.md
```

**Nota:** O script `send_to_bq.py` carrega automaticamente o arquivo `.env` usando `python-dotenv`.

### üóÑÔ∏è Banco de Dados

```bash
# Ver tabelas do banco
sqlite3 dbs/movie_database.db ".tables"

# Ver filmes cadastrados
sqlite3 dbs/movie_database.db "SELECT titulo_dublado, ano, imdb FROM movies LIMIT 10;"

# Contar filmes no banco
sqlite3 dbs/movie_database.db "SELECT COUNT(*) FROM movies;"

# Ver estrutura da tabela
sqlite3 dbs/movie_database.db ".schema movies"
```

### üê≥ Docker

```bash
# Build da imagem
docker build -t scraper-filmes -f deploy/Dockerfile .

# Executar com docker-compose
docker-compose -f deploy/docker-compose.yaml up

# Parar containers
docker-compose -f deploy/docker-compose.yaml down

# Ver logs
docker-compose -f deploy/docker-compose.yaml logs -f
```

### üßπ Utilit√°rios

```bash
# Limpar cache Python
find . -type d -name "__pycache__" -exec rm -r {} +
find . -type f -name "*.pyc" -delete

# Ver vers√£o do Python
python --version

# Ver localiza√ß√£o do ambiente virtual UV
which python
```

## üì¶ Estrutura de Dados

### Campos do Filme

| Campo            | Tipo    | Descri√ß√£o                    |
|------------------|---------|------------------------------|
| titulo_dublado   | STRING  | T√≠tulo em portugu√™s          |
| titulo_original  | STRING  | T√≠tulo original              |
| imdb             | FLOAT   | Nota do IMDB                 |
| ano              | INTEGER | Ano de lan√ßamento            |
| genero           | STRING  | G√™neros (separados por ",")  |
| tamanho          | STRING  | Tamanho do arquivo (GB)      |
| duracao_minutos  | INTEGER | Dura√ß√£o em minutos           |
| qualidade_video  | FLOAT   | Qualidade do v√≠deo (0-10)    |
| qualidade        | STRING  | Qualidade (1080p, 720p, etc) |
| dublado          | BOOLEAN | Se est√° dublado              |
| sinopse          | STRING  | Sinopse do filme             |
| link             | STRING  | URL do torrent               |

## üê≥ Docker

```bash
# Build da imagem
docker build -t scraper-filmes -f deploy/Dockerfile .

# Executar com docker-compose
docker-compose -f deploy/docker-compose.yaml up
```

## üìö Documenta√ß√£o

- [CLAUDE.md](docs/CLAUDE.md) - Documenta√ß√£o completa do projeto
- [BIGQUERY_SETUP.md](docs/BIGQUERY_SETUP.md) - Guia de configura√ß√£o do BigQuery
- [PREFECT_DEPLOYMENT.md](docs/PREFECT_DEPLOYMENT.md) - Guia completo de deployment com Prefect

## üõ†Ô∏è Tecnologias

- **Python 3.11+**
- **UV** - Gerenciamento de depend√™ncias
- **BeautifulSoup4** - Parsing de HTML
- **Pydantic** - Valida√ß√£o de dados
- **SQLAlchemy** - ORM para SQLite
- **Prefect** - Orquestra√ß√£o de workflows
- **Google Cloud BigQuery** - Data warehouse (opcional)
- **Docker** - Containeriza√ß√£o

## üìù Licen√ßa

Este projeto √© para fins educacionais.
